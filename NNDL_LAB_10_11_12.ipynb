{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MQHLrUTcHfOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "033f4473-234b-44fa-b2db-715776f1a486"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded 924 images with shape: (924, 128, 128, 3)\n",
            "\n",
            "ğŸ§  Training CNN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.1390 - loss: 6.0191 - val_accuracy: 0.2541 - val_loss: 2.4177\n",
            "Epoch 2/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 986ms/step - accuracy: 0.2790 - loss: 2.3823 - val_accuracy: 0.2541 - val_loss: 2.2961\n",
            "Epoch 3/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - accuracy: 0.2587 - loss: 2.2706 - val_accuracy: 0.2541 - val_loss: 2.2001\n",
            "Epoch 4/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 912ms/step - accuracy: 0.2953 - loss: 2.1795 - val_accuracy: 0.3081 - val_loss: 2.1416\n",
            "Epoch 5/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 991ms/step - accuracy: 0.3161 - loss: 2.0644 - val_accuracy: 0.3568 - val_loss: 2.0197\n",
            "Epoch 6/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 973ms/step - accuracy: 0.3437 - loss: 2.0034 - val_accuracy: 0.3946 - val_loss: 1.9618\n",
            "Epoch 7/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.3779 - loss: 1.8962 - val_accuracy: 0.4595 - val_loss: 1.8240\n",
            "Epoch 8/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 924ms/step - accuracy: 0.4131 - loss: 1.7983 - val_accuracy: 0.3892 - val_loss: 1.8526\n",
            "Epoch 9/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 969ms/step - accuracy: 0.4423 - loss: 1.7729 - val_accuracy: 0.4541 - val_loss: 1.7730\n",
            "Epoch 10/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 971ms/step - accuracy: 0.4481 - loss: 1.7596 - val_accuracy: 0.5297 - val_loss: 1.7358\n",
            "ğŸ“Š CNN Results:\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step\n",
            "Accuracy : 0.5297297297297298\n",
            "Precision: 0.5494233844233845\n",
            "Recall   : 0.5297297297297298\n",
            "F1 Score : 0.5174708982940772\n",
            "\n",
            "ğŸ§  Training RNN...\n",
            "Epoch 1/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.1926 - loss: 2.1971 - val_accuracy: 0.2432 - val_loss: 2.0027\n",
            "Epoch 2/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.2346 - loss: 2.0134 - val_accuracy: 0.2378 - val_loss: 2.0044\n",
            "Epoch 3/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2880 - loss: 1.9580 - val_accuracy: 0.1784 - val_loss: 2.0104\n",
            "Epoch 4/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2917 - loss: 1.9335 - val_accuracy: 0.2432 - val_loss: 2.0106\n",
            "ğŸ“Š RNN Results:\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Accuracy : 0.24324324324324326\n",
            "Precision: 0.0790985596374818\n",
            "Recall   : 0.24324324324324326\n",
            "F1 Score : 0.11195523345056053\n",
            "\n",
            "ğŸ§  Training Bidirectional RNN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.1878 - loss: 2.2699 - val_accuracy: 0.2324 - val_loss: 1.9812\n",
            "Epoch 2/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2361 - loss: 2.0073 - val_accuracy: 0.2378 - val_loss: 2.0039\n",
            "Epoch 3/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.2466 - loss: 1.9740 - val_accuracy: 0.2811 - val_loss: 1.9990\n",
            "Epoch 4/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.3082 - loss: 1.9016 - val_accuracy: 0.2595 - val_loss: 1.9506\n",
            "Epoch 5/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.2995 - loss: 1.8593 - val_accuracy: 0.2811 - val_loss: 1.9581\n",
            "Epoch 6/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.3546 - loss: 1.8016 - val_accuracy: 0.2811 - val_loss: 1.9531\n",
            "Epoch 7/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.3630 - loss: 1.7718 - val_accuracy: 0.2703 - val_loss: 1.9148\n",
            "Epoch 8/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.4140 - loss: 1.7044 - val_accuracy: 0.2865 - val_loss: 1.9124\n",
            "Epoch 9/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.3586 - loss: 1.7772 - val_accuracy: 0.2595 - val_loss: 1.9522\n",
            "Epoch 10/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.3769 - loss: 1.6997 - val_accuracy: 0.1892 - val_loss: 2.1310\n",
            "ğŸ“Š Bidirectional RNN Results:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7bc515306980> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step\n",
            "Accuracy : 0.2864864864864865\n",
            "Precision: 0.24348660348660348\n",
            "Recall   : 0.2864864864864865\n",
            "F1 Score : 0.20842995768269376\n",
            "\n",
            "ğŸ§  Training LSTM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 355ms/step - accuracy: 0.2158 - loss: 2.0947 - val_accuracy: 0.2541 - val_loss: 1.9870\n",
            "Epoch 2/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.2552 - loss: 1.9742 - val_accuracy: 0.2486 - val_loss: 1.9338\n",
            "Epoch 3/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 329ms/step - accuracy: 0.2886 - loss: 1.9231 - val_accuracy: 0.2757 - val_loss: 1.9435\n",
            "Epoch 4/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 271ms/step - accuracy: 0.3115 - loss: 1.8903 - val_accuracy: 0.2811 - val_loss: 1.9229\n",
            "Epoch 5/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 235ms/step - accuracy: 0.3110 - loss: 1.8718 - val_accuracy: 0.2811 - val_loss: 1.8707\n",
            "Epoch 6/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 237ms/step - accuracy: 0.3672 - loss: 1.8230 - val_accuracy: 0.2703 - val_loss: 1.8524\n",
            "Epoch 7/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 298ms/step - accuracy: 0.3545 - loss: 1.7744 - val_accuracy: 0.2919 - val_loss: 1.8537\n",
            "Epoch 8/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 317ms/step - accuracy: 0.3691 - loss: 1.7432 - val_accuracy: 0.2865 - val_loss: 1.8764\n",
            "Epoch 9/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 227ms/step - accuracy: 0.3449 - loss: 1.7526 - val_accuracy: 0.2649 - val_loss: 1.8386\n",
            "Epoch 10/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 264ms/step - accuracy: 0.3738 - loss: 1.7428 - val_accuracy: 0.3081 - val_loss: 1.8150\n",
            "ğŸ“Š LSTM Results:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7bc51481f9c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step\n",
            "Accuracy : 0.3081081081081081\n",
            "Precision: 0.3125977094829554\n",
            "Recall   : 0.3081081081081081\n",
            "F1 Score : 0.2553207011364585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# =================== IMPORTS ===================\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras import layers, models, regularizers, Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# =================== MOUNT DRIVE ===================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# =================== SETUP ===================\n",
        "dataset_path = \"/content/drive/MyDrive/NNDL Dataset/Dataset\"\n",
        "categories = [\n",
        "    \"gond painting\", \"kalighat painting\", \"kangra painting\", \"kerala mural\",\n",
        "    \"madhubani painting\", \"mandana art drawing\", \"pichwai painting\", \"warli painting\"\n",
        "]\n",
        "img_size = (128, 128)\n",
        "valid_extensions = (\".jpg\", \".jpeg\", \".png\")\n",
        "\n",
        "# =================== LOAD IMAGES ===================\n",
        "def load_images(folder_path, img_size):\n",
        "    images, labels = [], []\n",
        "    for category in categories:\n",
        "        category_path = os.path.join(folder_path, category)\n",
        "        if not os.path.exists(category_path):\n",
        "            print(f\"âš ï¸ Warning: {category_path} does not exist. Skipping.\")\n",
        "            continue\n",
        "        for filename in os.listdir(category_path):\n",
        "            if filename.lower().endswith(valid_extensions):\n",
        "                img_path = os.path.join(category_path, filename)\n",
        "                img = load_img(img_path, target_size=img_size)\n",
        "                img_array = img_to_array(img) / 255.0\n",
        "                images.append(img_array)\n",
        "                labels.append(categories.index(category))\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "X, y = load_images(dataset_path, img_size)\n",
        "if len(X) == 0:\n",
        "    raise ValueError(\"No images were loaded. Please check your dataset folder structure.\")\n",
        "print(f\"âœ… Loaded {len(X)} images with shape: {X.shape}\")\n",
        "\n",
        "# =================== SPLIT DATA ===================\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# =================== CNN MODEL ===================\n",
        "def build_cnn_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3),\n",
        "                      kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(len(categories), activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# =================== EVALUATION FUNCTION ===================\n",
        "def evaluate_model(model, X_val, y_val):\n",
        "    y_pred = np.argmax(model.predict(X_val), axis=1)\n",
        "    print(\"Accuracy :\", accuracy_score(y_val, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_val, y_pred, average='weighted'))\n",
        "    print(\"Recall   :\", recall_score(y_val, y_pred, average='weighted'))\n",
        "    print(\"F1 Score :\", f1_score(y_val, y_pred, average='weighted'))\n",
        "\n",
        "# =================== RNN PREPROCESSING ===================\n",
        "X_rnn = X.reshape(-1, 128, 128 * 3)\n",
        "X_train_rnn, X_val_rnn = train_test_split(X_rnn, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# =================== RNN MODEL ===================\n",
        "def build_rnn_model():\n",
        "    inputs = layers.Input(shape=(128, 384))\n",
        "    x = layers.SimpleRNN(64)(inputs)\n",
        "    outputs = layers.Dense(len(categories), activation='softmax')(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# =================== BIDIRECTIONAL RNN ===================\n",
        "def build_bidirectional_rnn_model():\n",
        "    inputs = layers.Input(shape=(128, 384))\n",
        "    x = layers.Bidirectional(layers.SimpleRNN(64))(inputs)\n",
        "    outputs = layers.Dense(len(categories), activation='softmax')(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# =================== LSTM MODEL ===================\n",
        "def build_lstm_model():\n",
        "    inputs = layers.Input(shape=(128, 384))\n",
        "    x = layers.Bidirectional(layers.LSTM(64))(inputs)\n",
        "    outputs = layers.Dense(len(categories), activation='softmax')(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# =================== EARLY STOP ===================\n",
        "early_stop = EarlyStopping(patience=3, restore_best_weights=True)\n",
        "\n",
        "# =================== TRAIN AND EVALUATE ALL MODELS ===================\n",
        "# CNN\n",
        "print(\"\\nğŸ§  Training CNN...\")\n",
        "cnn_model = build_cnn_model()\n",
        "cnn_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, callbacks=[early_stop])\n",
        "print(\"ğŸ“Š CNN Results:\")\n",
        "evaluate_model(cnn_model, X_val, y_val)\n",
        "\n",
        "# RNN\n",
        "print(\"\\nğŸ§  Training RNN...\")\n",
        "rnn_model = build_rnn_model()\n",
        "rnn_model.fit(X_train_rnn, y_train, validation_data=(X_val_rnn, y_val), epochs=10, callbacks=[early_stop])\n",
        "print(\"ğŸ“Š RNN Results:\")\n",
        "evaluate_model(rnn_model, X_val_rnn, y_val)\n",
        "\n",
        "# Bidirectional RNN\n",
        "print(\"\\nğŸ§  Training Bidirectional RNN...\")\n",
        "bidir_rnn_model = build_bidirectional_rnn_model()\n",
        "bidir_rnn_model.fit(X_train_rnn, y_train, validation_data=(X_val_rnn, y_val), epochs=10, callbacks=[early_stop])\n",
        "print(\"ğŸ“Š Bidirectional RNN Results:\")\n",
        "evaluate_model(bidir_rnn_model, X_val_rnn, y_val)\n",
        "\n",
        "# LSTM\n",
        "print(\"\\nğŸ§  Training LSTM...\")\n",
        "lstm_model = build_lstm_model()\n",
        "lstm_model.fit(X_train_rnn, y_train, validation_data=(X_val_rnn, y_val), epochs=10, callbacks=[early_stop])\n",
        "print(\"ğŸ“Š LSTM Results:\")\n",
        "evaluate_model(lstm_model, X_val_rnn, y_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRHjYzLJJS9p",
        "outputId": "b95cb623-e7e2-4372-bfd5-d8894735b60f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}